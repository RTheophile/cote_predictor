{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import nbadata \n",
    "import datetime as dt\n",
    "import feature_computer as ft\n",
    "import ml_tools as ml\n",
    "import simulator as sml \n",
    "import aside_analysis as aa\n",
    " \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "  \n",
    "# !!---------------------------------------------------------------------------------------------------!!\n",
    "# !! From NbaDataSg first call to df_features computing, ~4h30 are necessary to computes all resources !!\n",
    "# !! Feel free to use pre-processed pickles in order to skip this long process                         !! \n",
    "# !!---------------------------------------------------------------------------------------------------!!\n",
    "\n",
    "# Parameter : \n",
    "# Simulation number for part 1 & 2.\n",
    "# ~20 minutes with a laptop are enought to compute 50 000 simulations\n",
    "sim_count = 50000\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "#----------------------------- Part 0 : preprocessing & Features extraction    \n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "# How possibly this thing could take so long ??\n",
    "# For each player in every game we have to identify what was the previous game where he was involved and I\n",
    "# do it two times  \n",
    "#   - Compute the player team ! We do not have this information at start. We know playerX played this day \n",
    "#     in this game but on which side ? we have to take a look on the ~10 closest game to have a clear idea\n",
    "#     (ID) of the player side in a single game.\n",
    "#   - Compute the player past stats : Player X played in this team this day, then in an other team... what\n",
    "#     are his records ? For each game we want to know the team complete records.\n",
    "#\n",
    "# Most of this is Hidden in libs. It was very time consuming.  \n",
    "\n",
    "# I know singleton are ugly but... all this python data manipulation is ugly too.\n",
    "# All of this should have been done with an SGBD.\n",
    "# This part generates a lot of \"files not found\" messages if your are computing the dataset yourself.\n",
    "# If you compute them please understand there is 3 ways to get the 2 basics dataset\n",
    "#   1. Load them from pickles files named 'df_players' and 'df_games'\n",
    "#   2. Download them from S3 repository with a well configurated Boto3 library (the provided method)\n",
    "#   3. Download them from S3 repository with login. You will have to create a credentials.txt file in the project\n",
    "#      root directory and filled it with {aws_access_key_id}/{aws_secret_access_key}\n",
    "resources = nbadata.NbaDataSg()\n",
    "\n",
    "start_date_season_2018 = dt.date(2018, 10, 16)\n",
    "start_date_playoff_2018 = dt.date(2019, 4, 13)\n",
    " \n",
    "# Computes features by players\n",
    "fc = ft.feature_computer() \n",
    "resources.df_player_histo = fc.compute_players_features(resources.df_player_conso, start_date_season_2018)\n",
    "\n",
    "# Computes features by team\n",
    "resources.df_games_histo = fc.compute_teams_features(resources.df_games, start_date_season_2018)\n",
    "\n",
    "# Merge players data into one dataset containing all imagined features \n",
    "df_features, feature_glossary = fc.compute_df_features(resources.df_player_histo, resources.df_games_histo)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "#----------------------------- Part 1 :  Regular Season begin, let's predict a cote for each team !             ---\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "# How to do ?\n",
    "# 1. Make a game outcome predictor wich gives a probability for home team to beat way team\n",
    "#   1.1 Use PCA on df_feature to get synthetic component of team A & B statistics on the previous seasons data\n",
    "#   1.2 Train a logistic regression on pca components\n",
    "#   1.3 Use the 2018 regular season data as a game agenda and use the model to estimate the home victory porobability\n",
    "#       for each game\n",
    "# 2. Simulate the NBA thousand of times\n",
    "#   2.1 Simulate regular season\n",
    "#   2.2 Simulate playoff with the regular season simulation as an input and get a NBA winner\n",
    "# 3. Compute Cotes\n",
    "#   3.1 If a team win 50% of the simulations, his cote should be 2\n",
    "#   3.2 Think about the models limits before betting any euro. \n",
    "#       Hight cotes should not be estimated with this model.\n",
    "\n",
    "# PCA is fitted on 2001_2017 time interval : 2000 lack of data and 2018 is supposed unknown\n",
    "# 2000 data are usefull for building 2001 & 2002 stats but not more\n",
    "df_2001_2017 = df_features[(df_features.season > 2000) & (df_features.season < 2018)] \n",
    "histo_pca = ml.get_pca(df_2001_2017, feature_glossary['home'], 5)\n",
    " \n",
    "# Each team's features are rotated with the PCA and components added to our data frame as new features \n",
    "df_2001_2018 = df_features[df_features.season > 2000]\n",
    "df_2001_2018, feature_glossary = ml.add_pca_conponent_as_features(df_2001_2018, feature_glossary, histo_pca, 5)\n",
    " \n",
    "# A model is trained with previous season :  \n",
    "df_2018 = df_2001_2018[df_2001_2018.season<2018]\n",
    "logistic_reg = ml.train_model(df_2018, feature_glossary['pca_components'])\n",
    "\n",
    "# Predict outcome probability for each regular season games \n",
    "df_reg_season = df_2001_2018[(df_2001_2018.season==2018) & (df_2001_2018.datetime < start_date_playoff_2018)]\n",
    "df_reg_season = df_reg_season.assign(prediction=[x[1] for x in logistic_reg.predict_proba(df_reg_season[feature_glossary['pca_components']])])\n",
    "\n",
    "# Compute all the 1 to 1 matchups \n",
    "df_matchups = df_2001_2018[df_2001_2018.season==2018]\n",
    "df_matchups = df_matchups.assign(prediction=[x[1] for x in logistic_reg.predict_proba(df_matchups[feature_glossary['pca_components']])])\n",
    "df_matchups = df_matchups[['home_id', 'away_id', 'prediction']].groupby(['home_id', 'away_id']).apply(np.mean)\n",
    "\n",
    "# Here a NBA simulator. Many details and rules are missing but it is still very realistic.\n",
    "sim = sml.Simulator() \n",
    " \n",
    "# Lauch X simulations\n",
    "df_win_sim = pd.DataFrame(range(sim_count), columns=['wins'])\n",
    "df_win_sim['team_id']= df_win_sim.apply(lambda x: sim.simulate_nba(df_reg_season, df_matchups), axis=1)\n",
    "  \n",
    "# Count wins by teams \n",
    "df_win_sim = df_win_sim.groupby(['team_id']).count().sort_values(['wins'], ascending=False).reset_index()\n",
    "\n",
    "# Make it readable with team names\n",
    "df_cotes_before = pd.merge(sim.team_div_conf, df_win_sim, how='inner', left_on=['team_id'], right_on=['team_id'])\n",
    "\n",
    "# Compute Cote \n",
    "df_cotes_before = df_cotes_before.assign(win_pct=lambda x: x.wins / sim_count) \n",
    "df_cotes_before = df_cotes_before.assign(cote=lambda x: round(1 / x.win_pct,2) ) \n",
    "\n",
    "print('A cote has been evaluated for each team before the regular season')\n",
    "\n",
    "# Export Result\n",
    "df_cotes_before.to_csv('cote_nba_before_regular_season.csv', decimal=',', sep=';', index=False)\n",
    "aa.show_simulation_result(df_cotes_before)  \n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "#----------------------------- Part 2 :  Regular Season is over, let's predict an updated cote for each team !  ---\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "# Here, we use the same methodology with the followings changes :\n",
    "#  1. Regular season games are used as training data set.\n",
    "#     - We won't recompute all the data here, I did it for you using the very same process with nbadata just by \n",
    "#       changing the 'max known date' in 'fc.compute_players_features' in & 'fc.compute_teams_features'. Of course I could have recompute only the regular season data but I did not want to \n",
    "#       spend more time on this painfull data processing part.\n",
    "#     - I could have drop all the data post regular season, it would have been more elegant. Id did not in order to \n",
    "#       facilitate the matchup definition.\n",
    "#       \n",
    "#  2. The simulator will simulate only the playoff simulator. \n",
    "#     - Two files are needed ranking_est.csv & ranking_ouest.csv and give the tournament structure.\n",
    "#     - Fill free to play with the the simulations number  \n",
    "#\n",
    "    \n",
    "# Get an updated features dataframe where all kpi's take into account the 2018 regular season\n",
    "df_features_playoff = pd.read_csv('df_features_playoff.csv', sep=';')\n",
    "df_features_playoff['datetime'] = df_features_playoff['datetime'].apply(pd.to_datetime)\n",
    "\n",
    "# New features are computed using PCA rotation \n",
    "df_2010_2018 = df_features_playoff[df_features_playoff.season > 2010]\n",
    "df_2010_2018, feature_glossary = ml.add_pca_conponent_as_features(df_2010_2018, feature_glossary, histo_pca, 5)\n",
    " \n",
    "# A model is trained with previous games including 2018 regular season:  \n",
    "df_training = df_2010_2018[df_2010_2018['datetime'] < pd.to_datetime(start_date_playoff_2018)]\n",
    "logistic_reg = ml.train_model(df_training, feature_glossary['pca_components'])\n",
    "\n",
    "# Predict outcome probability for each 2018 game\n",
    "df_2018 = df_2010_2018[df_2010_2018.season == 2018]\n",
    "df_2018 = df_2018.assign(prediction=[x[1] for x in logistic_reg.predict_proba(df_2018[feature_glossary['pca_components']])])\n",
    "\n",
    "# Now we have a win probability for every matchup \n",
    "df_matchups = df_2018[['home_id', 'away_id', 'prediction']].groupby(['home_id', 'away_id']).apply(np.mean)\n",
    "\n",
    "# Use the simulator\n",
    "sim = sml.Simulator() \n",
    "\n",
    "# Load 2018 regular season ranking by conferences\n",
    "ranking_E, ranking_O = pd.read_csv('ranking_est.csv', sep=';'), pd.read_csv('ranking_ouest.csv', sep=';')\n",
    "\n",
    "# Lauch X simulations \n",
    "playoff_simulation = pd.DataFrame(range(sim_count), columns=['wins'])\n",
    "playoff_simulation['team_id']= playoff_simulation.apply(lambda x: sim.simulate_playoff(df_matchups, ranking_E, ranking_O), axis=1)\n",
    "\n",
    "# Count wins by teams \n",
    "playoff_simulation_g = playoff_simulation.groupby(['team_id']).count().sort_values(['wins'], ascending=False).reset_index()\n",
    "\n",
    "# Make it readable with team names\n",
    "df_cotes_after = pd.merge(sim.team_div_conf, playoff_simulation_g, how='inner', left_on=['team_id'], right_on=['team_id'])\n",
    "\n",
    "# Compute Cote \n",
    "df_cotes_after = df_cotes_after.assign(win_pct=lambda x: x.wins / sim_count) \n",
    "df_cotes_after = df_cotes_after.assign(cote=lambda x: round(1 / x.win_pct,2) )  \n",
    "\n",
    "print('A cote has been evaluated for each team before the playoff')\n",
    "\n",
    "# Export Result \n",
    "df_cotes_after.to_csv('cote_nba_before_playoff.csv', decimal=',', sep=';', index=False) \n",
    "aa.show_simulation_result(df_cotes_after)  \n",
    "\n",
    "# How evolve the cotes after play off ?\n",
    "aa.show_cote_comparator(df_cotes_before, df_cotes_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contact pour toute question ou information supplÃ©mentaire : theophile.ravillion@gmail.com - 06.50.79.40.44"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
