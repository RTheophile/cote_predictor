{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Info : df_player_histo read from pickle\n",
      "Info : df_games_histo read from pickle\n",
      "Info : df_features read from pickle\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-4681dec500c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;31m# Lauch X simulations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[0mdf_win_sim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'wins'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m \u001b[0mdf_win_sim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'team_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdf_win_sim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulate_nba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_reg_season\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_matchups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;31m# Count wins by teams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ds\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   7546\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7547\u001b[0m         )\n\u001b[1;32m-> 7548\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7550\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"DataFrame\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ds\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ds\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ds\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                     \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                         \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-4681dec500c1>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;31m# Lauch X simulations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[0mdf_win_sim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'wins'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m \u001b[0mdf_win_sim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'team_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdf_win_sim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulate_nba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_reg_season\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_matchups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;31m# Count wins by teams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\DataScience\\betclic\\Official\\simulator.py\u001b[0m in \u001b[0;36msimulate_nba\u001b[1;34m(self, df_reg_season, df_matchups)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msimulate_nba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_reg_season\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_matchups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0msim_ranking_E\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim_ranking_O\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulate_season\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_reg_season\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulate_playoff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_matchups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim_ranking_E\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim_ranking_O\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\DataScience\\betclic\\Official\\simulator.py\u001b[0m in \u001b[0;36msimulate_season\u001b[1;34m(self, df_season)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msimulate_season\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_season\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# For each game, roll a dice to define a winner accordingly to probabilities for team A to win vs team B\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mdf_season\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'random'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_season\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mdf_season\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_season\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwins_home\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mdf_season\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_season\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwins_away\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ds\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3038\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3039\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3040\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ds\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3115\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3116\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3117\u001b[1;33m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3119\u001b[0m         \u001b[1;31m# check if we are modifying a copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ds\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3578\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3580\u001b[1;33m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iset_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3582\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ds\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_iset_item\u001b[1;34m(self, loc, value)\u001b[0m\n\u001b[0;32m   3567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iset_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3569\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3570\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ds\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36miset\u001b[1;34m(self, loc, value)\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[1;31m# Accessing public blknos ensures the public versions are initialized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m         \u001b[0mblknos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1087\u001b[1;33m         \u001b[0mblklocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1088\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[0munfit_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import nbadata \n",
    "import datetime as dt\n",
    "import feature_computer as ft\n",
    "import ml_tools as ml\n",
    "import simulator as sml \n",
    "import aside_analysis as aa\n",
    " \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "  \n",
    "# !!---------------------------------------------------------------------------------------------------!!\n",
    "# !! From NbaDataSg first call to df_features computing, ~4h30 are necessary to computes all resources !!\n",
    "# !! Feel free to use pre-processed pickles in order to skip this long process                         !! \n",
    "# !!---------------------------------------------------------------------------------------------------!!\n",
    "\n",
    "# Parameter : \n",
    "# Simulation number for part 1 & 2.\n",
    "# ~20 minutes with a laptop are enought to compute 50 000 simulations\n",
    "sim_count = 50000\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "#----------------------------- Part 0 : preprocessing & Features extraction    \n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "# How possibly this thing could take so long ??\n",
    "# For each player in every game we have to identify what was the previous game where he was involved and I\n",
    "# do it two times  \n",
    "#   - Compute the player team ! We do not have this information at start. We know playerX played this day \n",
    "#     in this game but on which side ? we have to take a look on the ~10 closest game to have a clear idea\n",
    "#     (ID) of the player side in a single game.\n",
    "#   - Compute the player past stats : Player X played in this team this day, then in an other team... what\n",
    "#     are his records ? For each game we want to know the team complete records.\n",
    "#\n",
    "# Most of this is Hidden in libs. It was very time consuming.  \n",
    "\n",
    "# I know singleton are ugly but... all this python data manipulation is ugly too.\n",
    "# All of this should have been done with an SGBD.\n",
    "# This part generates a lot of \"files not found\" messages if your are computing the dataset yourself.\n",
    "# If you compute them please understand there is 3 ways to get the 2 basics dataset\n",
    "#   1. Load them from pickles files named 'df_players' and 'df_games'\n",
    "#   2. Download them from S3 repository with a well configurated Boto3 library (the provided method)\n",
    "#   3. Download them from S3 repository with login. You will have to create a credentials.txt file in the project\n",
    "#      root directory and filled it with {aws_access_key_id}/{aws_secret_access_key}\n",
    "resources = nbadata.NbaDataSg()\n",
    "\n",
    "start_date_season_2018 = dt.date(2018, 10, 16)\n",
    "start_date_playoff_2018 = dt.date(2019, 4, 13)\n",
    " \n",
    "# Computes features by players\n",
    "fc = ft.feature_computer() \n",
    "resources.df_player_histo = fc.compute_players_features(resources.df_player_conso, start_date_season_2018)\n",
    "\n",
    "# Computes features by team\n",
    "resources.df_games_histo = fc.compute_teams_features(resources.df_games, start_date_season_2018)\n",
    "\n",
    "# Merge players data into one dataset containing all imagined features \n",
    "df_features, feature_glossary = fc.compute_df_features(resources.df_player_histo, resources.df_games_histo)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "#----------------------------- Part 1 :  Regular Season begin, let's predict a cote for each team !             ---\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "# How to do ?\n",
    "# 1. Make a game outcome predictor wich gives a probability for home team to beat way team\n",
    "#   1.1 Use PCA on df_feature to get synthetic component of team A & B statistics on the previous seasons data\n",
    "#   1.2 Train a logistic regression on pca components\n",
    "#   1.3 Use the 2018 regular season data as a game agenda and use the model to estimate the home victory porobability\n",
    "#       for each game\n",
    "# 2. Simulate the NBA thousand of times\n",
    "#   2.1 Simulate regular season\n",
    "#   2.2 Simulate playoff with the regular season simulation as an input and get a NBA winner\n",
    "# 3. Compute Cotes\n",
    "#   3.1 If a team win 50% of the simulations, his cote should be 2\n",
    "#   3.2 Think about the models limits before betting any euro. \n",
    "#       Hight cotes should not be estimated with this model.\n",
    "\n",
    "# PCA is fitted on 2001_2017 time interval : 2000 lack of data and 2018 is supposed unknown\n",
    "# 2000 data are usefull for building 2001 & 2002 stats but not more\n",
    "df_2001_2017 = df_features[(df_features.season > 2000) & (df_features.season < 2018)] \n",
    "histo_pca = ml.get_pca(df_2001_2017, feature_glossary['home'], 5)\n",
    " \n",
    "# Each team's features are rotated with the PCA and components added to our data frame as new features \n",
    "df_2001_2018 = df_features[df_features.season > 2000]\n",
    "df_2001_2018, feature_glossary = ml.add_pca_conponent_as_features(df_2001_2018, feature_glossary, histo_pca, 5)\n",
    " \n",
    "# A model is trained with previous season :  \n",
    "df_2018 = df_2001_2018[df_2001_2018.season<2018]\n",
    "logistic_reg = ml.train_model(df_2018, feature_glossary['pca_components'])\n",
    "\n",
    "# Predict outcome probability for each regular season games \n",
    "df_reg_season = df_2001_2018[(df_2001_2018.season==2018) & (df_2001_2018.datetime < start_date_playoff_2018)]\n",
    "df_reg_season = df_reg_season.assign(prediction=[x[1] for x in logistic_reg.predict_proba(df_reg_season[feature_glossary['pca_components']])])\n",
    "\n",
    "# Compute all the 1 to 1 matchups \n",
    "df_matchups = df_2001_2018[df_2001_2018.season==2018]\n",
    "df_matchups = df_matchups.assign(prediction=[x[1] for x in logistic_reg.predict_proba(df_matchups[feature_glossary['pca_components']])])\n",
    "df_matchups = df_matchups[['home_id', 'away_id', 'prediction']].groupby(['home_id', 'away_id']).apply(np.mean)\n",
    "\n",
    "# Here a NBA simulator. Many details and rules are missing but it is still very realistic.\n",
    "sim = sml.Simulator() \n",
    " \n",
    "# Lauch X simulations\n",
    "df_win_sim = pd.DataFrame(range(sim_count), columns=['wins'])\n",
    "df_win_sim['team_id']= df_win_sim.apply(lambda x: sim.simulate_nba(df_reg_season, df_matchups), axis=1)\n",
    "  \n",
    "# Count wins by teams \n",
    "df_win_sim = df_win_sim.groupby(['team_id']).count().sort_values(['wins'], ascending=False).reset_index()\n",
    "\n",
    "# Make it readable with team names\n",
    "df_cotes_before = pd.merge(sim.team_div_conf, df_win_sim, how='inner', left_on=['team_id'], right_on=['team_id'])\n",
    "\n",
    "# Compute Cote \n",
    "df_cotes_before = df_cotes_before.assign(win_pct=lambda x: x.wins / sim_count) \n",
    "df_cotes_before = df_cotes_before.assign(cote=lambda x: round(1 / x.win_pct,2) ) \n",
    "\n",
    "print('A cote has been evaluated for each team before the regular season')\n",
    "\n",
    "# Export Result\n",
    "df_cotes_before.to_csv('cote_nba_before_regular_season.csv', decimal=',', sep=';', index=False)\n",
    "aa.show_simulation_result(df_cotes_before)  \n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "#----------------------------- Part 2 :  Regular Season is over, let's predict an updated cote for each team !  ---\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "# Here, we use the same methodology with the followings changes :\n",
    "#  1. Regular season games are used as training data set.\n",
    "#     - We won't recompute all the data here, I did it for you using the very same process with nbadata just by \n",
    "#       changing the 'max known date' in 'fc.compute_players_features' in & 'fc.compute_teams_features'. Of course I could have recompute only the regular season data but I did not want to \n",
    "#       spend more time on this painfull data processing part.\n",
    "#     - I could have drop all the data post regular season, it would have been more elegant. Id did not in order to \n",
    "#       facilitate the matchup definition.\n",
    "#       \n",
    "#  2. The simulator will simulate only the playoff simulator. \n",
    "#     - Two files are needed ranking_est.csv & ranking_ouest.csv and give the tournament structure.\n",
    "#     - Fill free to play with the the simulations number  \n",
    "#\n",
    "    \n",
    "# Get an updated features dataframe where all kpi's take into account the 2018 regular season\n",
    "df_features_playoff = pd.read_csv('df_features_playoff.csv', sep=';')\n",
    "df_features_playoff['datetime'] = df_features_playoff['datetime'].apply(pd.to_datetime)\n",
    "\n",
    "# New features are computed using PCA rotation \n",
    "df_2010_2018 = df_features_playoff[df_features_playoff.season > 2010]\n",
    "df_2010_2018, feature_glossary = ml.add_pca_conponent_as_features(df_2010_2018, feature_glossary, histo_pca, 5)\n",
    " \n",
    "# A model is trained with previous games including 2018 regular season:  \n",
    "df_training = df_2010_2018[df_2010_2018['datetime'] < pd.to_datetime(start_date_playoff_2018)]\n",
    "logistic_reg = ml.train_model(df_training, feature_glossary['pca_components'])\n",
    "\n",
    "# Predict outcome probability for each 2018 game\n",
    "df_2018 = df_2010_2018[df_2010_2018.season == 2018]\n",
    "df_2018 = df_2018.assign(prediction=[x[1] for x in logistic_reg.predict_proba(df_2018[feature_glossary['pca_components']])])\n",
    "\n",
    "# Now we have a win probability for every matchup \n",
    "df_matchups = df_2018[['home_id', 'away_id', 'prediction']].groupby(['home_id', 'away_id']).apply(np.mean)\n",
    "\n",
    "# Use the simulator\n",
    "sim = sml.Simulator() \n",
    "\n",
    "# Load 2018 regular season ranking by conferences\n",
    "ranking_E, ranking_O = pd.read_csv('ranking_est.csv', sep=';'), pd.read_csv('ranking_ouest.csv', sep=';')\n",
    "\n",
    "# Lauch X simulations \n",
    "playoff_simulation = pd.DataFrame(range(sim_count), columns=['wins'])\n",
    "playoff_simulation['team_id']= playoff_simulation.apply(lambda x: sim.simulate_playoff(df_matchups, ranking_E, ranking_O), axis=1)\n",
    "\n",
    "# Count wins by teams \n",
    "playoff_simulation_g = playoff_simulation.groupby(['team_id']).count().sort_values(['wins'], ascending=False).reset_index()\n",
    "\n",
    "# Make it readable with team names\n",
    "df_cotes_after = pd.merge(sim.team_div_conf, playoff_simulation_g, how='inner', left_on=['team_id'], right_on=['team_id'])\n",
    "\n",
    "# Compute Cote \n",
    "df_cotes_after = df_cotes_after.assign(win_pct=lambda x: x.wins / sim_count) \n",
    "df_cotes_after = df_cotes_after.assign(cote=lambda x: round(1 / x.win_pct,2) )  \n",
    "\n",
    "print('A cote has been evaluated for each team before the playoff')\n",
    "\n",
    "# Export Result \n",
    "df_cotes_after.to_csv('cote_nba_before_playoff.csv', decimal=',', sep=';', index=False) \n",
    "aa.show_simulation_result(df_cotes_after)  \n",
    "\n",
    "# How evolve the cotes after play off ?\n",
    "aa.show_cote_comparator(df_cotes_before, df_cotes_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contact pour toute question ou information supplÃ©mentaire : theophile.ravillion@gmail.com - 06.50.79.40.44"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
